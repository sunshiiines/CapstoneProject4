# -*- coding: utf-8 -*-
"""Dataset_Group4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q4-kW9j1F9cEmXpYXZP5F_kW6f99TfHW
"""

import pandas as pd
import numpy as np

data = pd.read_csv('data_hypertension.csv')

# Set the maximum number of columns to display
pd.set_option('display.max_columns', None)

data.head(10)

# from google.colab import drive
# drive.mount('/content/drive')

# list columns headers
data.columns

data.describe()

data = data.drop(['Pregnancy','Level_of_Hemoglobin','Adrenal_and_thyroid_disorders'],axis =1)
data.head()

"""# Exploring Dataset"""

data.shape   #'a' and 'b' columns

data.info()

data.isnull().sum()

# drop values
data.dropna(inplace=True)

# Fill the data with mean
data['alcohol_consumption_per_day'].fillna(data['alcohol_consumption_per_day'].mean(), inplace=True)

data.head()

data.head(10)

data.to_csv('cleaned_dataset.csv', index=False)

"""# ML Models

# Logistic Regression
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

# X.head()

# y.head(10)

#define the predictor variables and the response variable
X = data[['Genetic_Pedigree_Coefficient','Age','BMI','Sex','Smoking','Physical_activity','salt_content_in_the_diet','alcohol_consumption_per_day','Level_of_Stress','Chronic_kidney_disease']]
# X = data.drop['Blood_Pressure_Abnormality',axis =1]

y = data['Blood_Pressure_Abnormality']



#split the dataset into training (70%) and testing (30%) sets
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=40)

print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score

# Instantiate the model
log_regression = LogisticRegression()

# Fit the model using the training data
log_regression.fit(X_train, y_train)

# Use the model to make predictions on the test data
y_pred = log_regression.predict(X_test)

# Calculate evaluation metrics
Accuracy_LR = accuracy_score(y_test, y_pred)
Recall_LR = recall_score(y_test, y_pred)
Precision_LR = precision_score(y_test, y_pred)
F1_score_LR = f1_score(y_test, y_pred)

print("1. Logistic Regression")
print("=========================================================================")
print('Accuracy for [LR]: %.3f' % (Accuracy_LR * 100))
print('Recall for [LR]: %.3f' % (Recall_LR * 100))
print('Precision for [LR]: %.3f' % (Precision_LR * 100))
print('F1 Score for [LR]: %.3f' % (F1_score_LR * 100))

cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

#define metrics
y_pred_proba = log_regression.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)

#create ROC curve
plt.plot(fpr,tpr,label="AUC="+str(auc))
plt.legend(loc=4)
plt.show()

"""# Support Vector Machine"""

# Import scikit-learn dataset library
from sklearn.svm import SVC
from sklearn.metrics import precision_score, recall_score,f1_score, accuracy_score,roc_auc_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

#instantiate the model
svc_mo = SVC()

#fit the model using the training data
svc_mo.fit(X_train,y_train)

#use model to make predictions on test data
y_pred_SVC = svc_mo.predict(X_test)


Accuracy_SVC = accuracy_score(y_test, y_pred_SVC)
Recall_SVC = recall_score(y_test, y_pred_SVC)
Precision_SVC = precision_score(y_test, y_pred_SVC)
F1_score_SVC = f1_score (y_test, y_pred_SVC)

print("5. SVC")
print("=========================================================================")
print('Accuracy for [SVC]: %.3f' % (Accuracy_SVC*100))
print('Recall for [SVC]: %.3f' % (Recall_SVC*100))
print('Precision for [SVC]: %.3f' % (Precision_SVC*100))
print('F1 Score for[SVC]: %.3f' % (F1_score_SVC*100))

"""# ADABOOST"""

from sklearn.ensemble import AdaBoostClassifier
from sklearn.datasets import make_classification


AB_MO = AdaBoostClassifier(n_estimators=100, random_state=0)

AB_MO = AB_MO.fit(X_train,y_train)

#use model to make predictions on test data
y_pred_AB = AB_MO.predict(X_test)

Accuracy_AB = accuracy_score(y_test, y_pred_AB)
Recall_AB = recall_score(y_test, y_pred_AB)
Precision_AB = precision_score(y_test, y_pred_AB)
F1_score_AB = f1_score (y_test, y_pred_AB)

print("6. ADABOOST")
print("=========================================================================")
print('Accuracy for [AB]: %.3f' % (Accuracy_AB*100))
print('Recall for [AB]: %.3f' % (Recall_AB*100))
print('Precision for [AB]: %.3f' % (Precision_AB*100))
print('F1 Score for[AB]: %.3f' % (F1_score_AB*100))

"""# KNeighborsClassifier"""

from sklearn.neighbors import KNeighborsClassifier

### Install
KNN_mo = KNeighborsClassifier(n_neighbors=3)

### Fitting
KNN_mo.fit(X_train,y_train)

### model prediction
y_pred_KNN = KNN_mo.predict(X_test)

Accuracy_KNN = accuracy_score(y_test, y_pred_KNN)
Recall_KNN = recall_score(y_test, y_pred_KNN)
Precision_KNN = precision_score(y_test, y_pred_KNN)
F1_score_KNN = f1_score (y_test, y_pred_KNN)

print("7. KNeighbors")
print("=========================================================================")
print('Accuracy for [KNN]: %.3f' % (Accuracy_KNN*100))
print('Recall for [KNN]: %.3f' % (Recall_KNN*100))
print('Precision for [KNN]: %.3f' % (Precision_KNN*100))
print('F1 Score for[KNN]: %.3f' % (F1_score_KNN*100))

"""# Naive Bayes"""

from sklearn.naive_bayes import GaussianNB

### Installation of the model
NB_mo=GaussianNB()

### Fitting
NB_mo.fit(X_train,y_train)

### model prediction
y_pred_NB = NB_mo.predict(X_test)

Accuracy_NB = accuracy_score(y_test, y_pred_NB)
Recall_NB = recall_score(y_test, y_pred_NB)
Precision_NB = precision_score(y_test, y_pred_NB)
F1_score_NB = f1_score (y_test, y_pred_NB)

print("8. Naive Bayes")
print("=========================================================================")
print('Accuracy for [NB]: %.3f' % (Accuracy_NB*100))
print('Recall for [NB]: %.3f' % (Recall_NB*100))
print('Precision for [NB]: %.3f' % (Precision_NB*100))
print('F1 Score for[NB]: %.3f' % (F1_score_NB*100))

"""# Random Forest Regression"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score

# Installation of the model
RF_MO = RandomForestClassifier(n_estimators=100, random_state=0)

# Fitting
RF_MO.fit(X_train, y_train)

# Model prediction
y_pred_RF = RF_MO.predict(X_test)

# Calculate evaluation metrics
Accuracy_RF = accuracy_score(y_test, y_pred_RF)
Recall_RF = recall_score(y_test, y_pred_RF)
Precision_RF = precision_score(y_test, y_pred_RF)
F1_score_RF = f1_score(y_test, y_pred_RF)

# Print evaluation metrics
print("9. Random Forest Classifier")
print("=========================================================================")
print('Accuracy for [RF]: %.3f' % (Accuracy_RF * 100))
print('Recall for [RF]: %.3f' % (Recall_RF * 100))
print('Precision for [RF]: %.3f' % (Precision_RF * 100))
print('F1 Score for [RF]: %.3f' % (F1_score_RF * 100))

"""# DecisionTreeClassifier"""

from sklearn.tree import DecisionTreeClassifier
DTclassifier = DecisionTreeClassifier(max_leaf_nodes=20)

DTclassifier.fit(X_train, y_train)

y_pred = DTclassifier.predict(X_test)

print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# Calculate evaluation metrics
Accuracy_DTclassifier = accuracy_score(y_test, y_pred)
Recall_DTclassifier= recall_score(y_test, y_pred)
Precision_DTclassifier= precision_score(y_test, y_pred)
F1_score_DTclassifier = f1_score(y_test, y_pred)

# Print evaluation metrics
print("11. Decision Tree Classifier")
print("=========================================================================")
print('Accuracy for [DTclassifier]: %.2f' % (Accuracy_DTclassifier * 100))
print('Recall for [DTclassifier]: %.2f' % (Recall_DTclassifier* 100))
print('Precision for [DTclassifier]: %.2f' % (Precision_DTclassifier * 100))
print('F1 Score for [DTclassifier]: %.2f' % (F1_score_DTclassifier* 100))

""" # ExtraTreesClassifier"""

from sklearn.ensemble import ExtraTreesClassifier
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Initialize the ExtraTreesClassifier model
ETC = ExtraTreesClassifier(n_estimators=100, random_state=0)

# Fit the model to the training data
ETC.fit(X_train, y_train)

# Make predictions on the test data
y_pred_ETC = ETC.predict(X_test)

# Calculate evaluation metrics
Accuracy_ETC_MA = accuracy_score(y_test, y_pred_ETC)
Precision_ETC_MA = precision_score(y_test, y_pred_ETC, average='micro')
Recall_ETC_MA = recall_score(y_test, y_pred_ETC, average='micro')
F1_score_ETC_MA = f1_score(y_test, y_pred_ETC, average='micro')

print("12. Extra Tree Classifier")
print("=========================================================================")
print('Accuracy for [MA] [ExtraTreesClassifier]: %.2f' % (Accuracy_ETC_MA*100))
print('Precision for[MA] [ExtraTreesClassifier]: %.2f' % (Precision_ETC_MA*100))
print('Recall for [MA] [ExtraTreesClassifier]: %.2f' % (Recall_ETC_MA*100))
print('F1 Score for[MA] [ExtraTreesClassifier]: %.2f' % (F1_score_ETC_MA*100))
print("=========================================================================")

"""# Neural network_mlp"""

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split

# # Split your data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the MLPClassifier with your desired hyperparameters
mlp_classifier = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)

# Fit the model to the training data
mlp_classifier.fit(X_train, y_train)

# Make predictions on the test data
y_pred = mlp_classifier.predict(X_test)

# Calculate evaluation metrics
Accuracy_mlp_classifier = accuracy_score(y_test, y_pred)
Precision_mlp_classifier = precision_score(y_test, y_pred)
Recall_mlp_classifier = recall_score(y_test, y_pred)
F1_score_mlp_classifier = f1_score(y_test, y_pred)

# Print the evaluation metrics

print("Neural Network Classifier")
print("========================================")
print('Accuracy for mlp_classifier [NeuralNetworkClassifier]: %.3f' % (Accuracy_mlp_classifier * 100))
print('Precision for mlp_classifier [NeuralNetworkClassifier]: %.3f' % (Precision_mlp_classifier * 100))
print('Recall for mlp_classifier [NeuralNetworkClassifier]: %.3f' % (Recall_mlp_classifier * 100))
print('F1 Score for mlp_classifier [NeuralNetworkClassifier]: %.3f' % (F1_score_mlp_classifier* 100))
print("========================================")

"""# Classification Model Predictions"""

import pickle

# Save the model to a file
with open('ETC.pkl', 'wb') as f:
    pickle.dump(ETC, f)

# Load the model from the file
with open('ETC.pkl', 'rb') as f:
    model3 = pickle.load(f)

# Make predictions using the loaded model
predictions = model3.predict([[0.23,54,33,1,0,26106,25333,205.0,3,0]])
print(predictions)

# model3.predict([[54,0,0,0,0,0,20]])
# model3.predict([[0.91,70,49,0,0,9995,29465,67.0,2,1]])
# model3.predict([[0.43,71,50,0,0,10635,7439,242.0,1,1]])
# model3.predict([[0.83,52,19,0,0,15619,49644,397.0,2,0]])
# model3.predict([[0.75,43,41,1,0,38369,32967,206.0,3,1])
# model3.predict([[0.41,48,20,0,0,29781,26749,134.0,2,0]])
# model3.predict([[0.68,72,44,0,0,814,9607,99.0,3,0]])
# model3.predict([[0.61,40,44,0,0,1278,12715,95.0,2,0]])
# model3.predict([[0.13,70,28,1,0,48527,26178,46.0,1,1]])
# model3.predict([[0.10,35,17,0,0,22500,43040,382.0,3,1]])

# Save the model to a file
with open('DTC.pkl', 'wb') as f:
    pickle.dump(ETC, f)

# Load the model from the file
with open('DTC.pkl', 'rb') as f:
    model4 = pickle.load(f)

# Make predictions using the loaded model
predictions = model4.predict ([[0.23,54,33,1,0,26106,25333,205.0,3,0]])
print(predictions)

#([[0.91,70,49,0,0,9995,29465,67.0,2,1]])

"""# Models Resampling"""

from imblearn.over_sampling import ADASYN

# Generate a synthetic imbalanced dataset
X, y = make_classification(n_classes=2, class_sep=2,
                           weights=[0.1, 0.9], n_informative=3,
                           n_redundant=1, flip_y=0, n_features=30,
                           n_clusters_per_class=1, n_samples=1000,
                           random_state=42)


# # Split your data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply ADASYN to balance the training dataset
adasyn = ADASYN(sampling_strategy='minority', random_state=42)
# adasyn = ADASYN(random_state=42)
X_resampled, y_resampled = adasyn.fit_resample(X_train,y_train)

"""# ETC"""

# Initialize the ExtraTreesClassifier model
ETC_resampled = ExtraTreesClassifier(n_estimators=100, random_state=0)

# Fit the model to the training data
ETC_resampled.fit(X_resampled, y_resampled)

# Make predictions on the test data
y_pred_ETC_resampled = ETC_resampled.predict(X_test)

# Calculate evaluation metrics
Accuracy_ETC_MA_resampled = accuracy_score(y_test, y_pred_ETC_resampled)
Precision_ETC_MA_resampled = precision_score(y_test, y_pred_ETC_resampled, average='micro')
Recall_ETC_MA_resampled = recall_score(y_test, y_pred_ETC_resampled, average='micro')
F1_score_ETC_MA_resampled = f1_score(y_test, y_pred_ETC_resampled, average='micro')

print("12. Extra Tree Classifier")
print("=========================================================================")
print('Accuracy for [MA] [ExtraTreesClassifier]: %.2f' % (Accuracy_ETC_MA_resampled*100))
print('Precision for[MA] [ExtraTreesClassifier]: %.2f' % (Precision_ETC_MA_resampled*100))
print('Recall for [MA] [ExtraTreesClassifier]: %.2f' % (Recall_ETC_MA_resampled*100))
print('F1 Score for[MA] [ExtraTreesClassifier]: %.2f' % (F1_score_ETC_MA_resampled*100))
print("=========================================================================")

"""# RTC"""

# Initialize the RandomForestClassifier model
RF_resampled = RandomForestClassifier(n_estimators=100, random_state=0)

# Fit the model to the training data
RF_resampled.fit(X_resampled, y_resampled)

# Make predictions on the test data
RF_resampled_TEST = RF_resampled.predict(X_test)

# Calculate evaluation metrics
Accuracy_RF_resampled = accuracy_score(y_test, RF_resampled_TEST)
Precision_RF_resampled = precision_score(y_test, RF_resampled_TEST)
Recall_RF_resampled = recall_score(y_test, RF_resampled_TEST)
F1_score_RF_resampled = f1_score(y_test, RF_resampled_TEST)

print("Random Forest Classifier")
print("=========================================================================")
print('Accuracy for [RF] [RandomForestClassifier]: %.2f' % (Accuracy_RF_resampled*100))
print('Precision for[RF] [RandomForestClassifier]: %.2f' % (Precision_RF_resampled*100))
print('Recall for [RF] [RandomForestClassifier]: %.2f' % (Recall_RF_resampled*100))
print('F1 Score for[RF] [RandomForestClassifier]: %.2f' % (F1_score_RF_resampled*100))
print("=========================================================================")

"""# DTC"""

# Initializing the model
DTclassifier_RESAMPLED = DecisionTreeClassifier(max_leaf_nodes=20)

DTclassifier_RESAMPLED.fit(X_resampled,y_resampled)

y_pred_RESAMPLED = DTclassifier_RESAMPLED.predict(X_test)

print(classification_report(y_test, y_pred_RESAMPLED))
print(confusion_matrix(y_test, y_pred_RESAMPLED))

# Calculate evaluation metrics
Accuracy_DTclassifier_RESAMPLED = accuracy_score(y_test, y_pred_RESAMPLED)
Recall_DTclassifier_RESAMPLED = recall_score(y_test, y_pred_RESAMPLED)
Precision_DTclassifier_RESAMPLED = precision_score(y_test,y_pred_RESAMPLED)
F1_score_DTclassifier_RESAMPLED = f1_score(y_test,y_pred_RESAMPLED)

# Print evaluation metrics
print("11. Decision Tree Classifier")
print("=========================================================================")
print('Accuracy for [DTclassifier]: %.2f' % (Accuracy_DTclassifier_RESAMPLED * 100))
print('Recall for [DTclassifier]: %.2f' % (Recall_DTclassifier_RESAMPLED * 100))
print('Precision for [DTclassifier]: %.2f' % (Precision_DTclassifier_RESAMPLED* 100))
print('F1 Score for [DTclassifier]: %.2f' % (F1_score_DTclassifier_RESAMPLED* 100))

"""# SVC"""

# Initializing the model
SVC_resampled = SVC()

#fit the model using the training data
SVC_resampled.fit(X_resampled, y_resampled)

#use model to make predictions on test data
SVC_resampled_TEST = SVC_resampled.predict(X_test)


Accuracy_SVC_resampled = accuracy_score(y_test, SVC_resampled_TEST)
Precision_SVC_resampled = precision_score(y_test, SVC_resampled_TEST)
Recall_SVC_resampled = recall_score(y_test, SVC_resampled_TEST)
F1_score_SVC_resampled = f1_score(y_test, SVC_resampled_TEST)


print("SVC")
print("=========================================================================")
print('Accuracy for [SVC] [SupportVectorMachineClassifier]: %.2f' % (Accuracy_SVC_resampled*100))
print('Precision for[SVC] [SupportVectorMachineClassifier]: %.2f' % (Precision_SVC_resampled*100))
print('Recall for [SVC] [SupportVectorMachineClassifier]: %.2f' % (Recall_SVC_resampled*100))
print('F1 Score for[SVC] [SupportVectorMachineClassifier]: %.2f' % (F1_score_SVC_resampled*100))
print("=========================================================================")

"""# LR"""

# Initializing of the model
LR_resampled = LogisticRegression()

#fit the model using the training data
LR_resampled.fit(X_resampled, y_resampled)

#use model to make predictions on test data
LR_resampled_TEST = LR_resampled.predict(X_test)

Accuracy_LR_resampled = accuracy_score(y_test, LR_resampled_TEST)
Precision_LR_resampled = precision_score(y_test, LR_resampled_TEST)
Recall_LR_resampled = recall_score(y_test, LR_resampled_TEST)
F1_score_LR_resampled = f1_score(y_test, LR_resampled_TEST)


print("Logistic Regression")
print("=========================================================================")
print('Accuracy for [LR] [LogisticRegression]: %.3f' % (Accuracy_LR_resampled*100))
print('Precision for[LR] [LogisticRegression]: %.3f' % (Precision_LR_resampled*100))
print('Recall for [LR] [LogisticRegression]: %.3f' % (Recall_LR_resampled*100))
print('F1 Score for[LR] [LogisticRegression]: %.3f' % (F1_score_LR_resampled*100))
print("=========================================================================")

"""# NB"""

# Initializing of the model
NB_resampled = GaussianNB()

#fit the model using the training data
NB_resampled.fit(X_resampled, y_resampled)

#use model to make predictions on test data
NB_resampled_TEST = NB_resampled.predict(X_test)

Accuracy_NB_resampled = accuracy_score(y_test, NB_resampled_TEST)
Precision_NB_resampled = precision_score(y_test, NB_resampled_TEST)
Recall_NB_resampled = recall_score(y_test, NB_resampled_TEST)
F1_score_NB_resampled = f1_score(y_test, NB_resampled_TEST)


print("Naive Bayes")
print("=========================================================================")
print('Accuracy for [NB] [NaiveBayesClassifier]: %.3f' % (Accuracy_NB_resampled*100))
print('Precision for[NB] [NaiveBayesClassifier]: %.3f' % (Precision_NB_resampled*100))
print('Recall for [NB] [NaiveBayesClassifier]: %.3f' % (Recall_NB_resampled*100))
print('F1 Score for[NB] [NaiveBayesClassifier]: %.3f' % (F1_score_NB_resampled*100))
print("=========================================================================")

"""# ADABOOST"""

# Initializing of the model
AB_resampled = AdaBoostClassifier(n_estimators=100, random_state=0)

#fit the model using the training data
AB_resampled.fit(X_resampled, y_resampled)

#use model to make predictions on test data
AB_resampled_TEST = AB_resampled.predict(X_test)


Accuracy_AB_resampled = accuracy_score(y_test, AB_resampled_TEST)
Precision_AB_resampled = precision_score(y_test, AB_resampled_TEST)
Recall_AB_resampled = recall_score(y_test, AB_resampled_TEST)
F1_score_AB_resampled = f1_score(y_test, AB_resampled_TEST)


print("ADABOOST")
print("=========================================================================")
print('Accuracy for [AB] [ADABoostClassifier]: %.3f' % (Accuracy_AB_resampled*100))
print('Precision for[AB] [ADABoostClassifier]: %.3f' % (Precision_AB_resampled*100))
print('Recall for [AB] [ADABoostClassifier]: %.3f' % (Recall_AB_resampled*100))
print('F1 Score for[AB] [ADABoostClassifier]: %.3f' % (F1_score_AB_resampled*100))
print("=========================================================================")

"""# KNN"""

# Initializing of the model
KNN_resampled = KNeighborsClassifier(n_neighbors=3)

#fit the model using the training data
KNN_resampled.fit(X_resampled, y_resampled)

#use model to make predictions on test data
KNN_resampled_TEST = KNN_resampled.predict(X_test)


Accuracy_KNN_resampled = accuracy_score(y_test, KNN_resampled_TEST)
Precision_KNN_resampled = precision_score(y_test, KNN_resampled_TEST)
Recall_KNN_resampled = recall_score(y_test, KNN_resampled_TEST)
F1_score_KNN_resampled = f1_score(y_test, KNN_resampled_TEST)


print("KNeighborsClassifier")
print("=========================================================================")
print('Accuracy for [KNN] [KNeighborsClassifier]: %.3f' % (Accuracy_KNN_resampled*100))
print('Precision for[KNN] [KNeighborsClassifier]: %.3f' % (Precision_KNN_resampled *100))
print('Recall for [KNN] [KNeighborsClassifier]: %.3f' % (Recall_KNN_resampled*100))
print('F1 Score for[KNN] [AKNeighborsClassifier]: %.3f' % (F1_score_KNN_resampled*100))
print("=========================================================================")

"""# NN"""

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split

# Split your data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Resample your training data (you can use ADASYN as you mentioned earlier)
from imblearn.over_sampling import ADASYN

adasyn = ADASYN(random_state=42)
X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)

# Initialize the MLPClassifier model
mlp_resampled = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)

# Fit the model to the resampled training data
mlp_resampled.fit(X_train_resampled, y_train_resampled)

# Make predictions on the test data
y_pred_mlp_resampled = mlp_resampled.predict(X_test)

# Calculate evaluation metrics
Accuracy_mlp_resampled = accuracy_score(y_test, y_pred_mlp_resampled)
Precision_mlp_resampled = precision_score(y_test, y_pred_mlp_resampled)
Recall_mlp_resampled = recall_score(y_test, y_pred_mlp_resampled)
F1_score_mlp_resampled = f1_score(y_test, y_pred_mlp_resampled)

print("Neural Network Classifier")
print("=========================================================================")
print('Accuracy for [MA] [Neural Network Classifier]: %.3f' % (Accuracy_mlp_resampled * 100))
print('Precision for [MA] [Neural Network Classifier]: %.3f' % (Precision_mlp_resampled * 100))
print('Recall for [MA] [Neural Network Classifier]: %.3f' % (Recall_mlp_resampled * 100))
print('F1 Score for [MA] [Neural Network Classifier]: %.3f' % (F1_score_mlp_resampled * 100))
print("=========================================================================")

"""# Collecting the results into a table"""

algorithm_classifiers = [' Model', 'ETC',' RFC',' DTC',' SVC','LR','NB','AC','KNN','NN']

data_classifier =[
     ["Accuracy",
      Accuracy_ETC_MA*100,
      Accuracy_RF*100,
      Accuracy_DTclassifier*100,
      Accuracy_SVC*100,
      Accuracy_LR*100,
      Accuracy_NB*100,
      Accuracy_AB*100,
      Accuracy_KNN*100,
      Accuracy_mlp_classifier*100

],
     ["Recall",
      Recall_ETC_MA*100,
      Recall_RF*100,
      Recall_DTclassifier* 100,
      Recall_SVC*100,
      Recall_LR*100,
      Recall_NB*100,
      Recall_AB*100,
      Recall_KNN*100,
      Recall_mlp_classifier*100

],
     ["Precision",
      Precision_ETC_MA*100,
      Precision_RF*100,
      Precision_DTclassifier*100,
      Precision_SVC*100,
      Precision_LR*100,
      Precision_NB*100,
      Precision_AB*100,
      Precision_KNN*100,
      Precision_mlp_classifier*100

],
     ["F1_score",
      F1_score_ETC_MA*100,
      F1_score_RF*100,
      F1_score_DTclassifier* 100,
      F1_score_SVC*100,
      F1_score_LR*100,
      F1_score_NB*100,
      F1_score_AB*100,
      F1_score_KNN*100,
      F1_score_mlp_classifier*100


]
     ]
df_table = pd.DataFrame(data_classifier, columns=algorithm_classifiers)
df_table = pd.DataFrame(df_table).round(2)

data_adasyn_classifier =[
     ["Accuracy",
      Accuracy_ETC_MA_resampled*100,
      Accuracy_RF_resampled*100,
      Accuracy_DTclassifier_RESAMPLED * 100,
      Accuracy_SVC_resampled*100,
      Accuracy_LR_resampled*100,
      Accuracy_NB_resampled*100,
      Accuracy_AB_resampled*100,
      Accuracy_KNN_resampled*100,
      Accuracy_mlp_resampled*100
],
     ["Precision",
      Precision_ETC_MA_resampled*100,
      Precision_RF_resampled*100,
      Precision_DTclassifier_RESAMPLED* 100,
      Precision_SVC_resampled*100,
      Precision_LR_resampled*100,
      Precision_NB_resampled*100,
      Precision_AB_resampled*100,
      Precision_KNN_resampled *100,
      Precision_mlp_resampled*100
],
     ["Recall",
      Recall_ETC_MA_resampled*100,
      Recall_RF_resampled*100,
      Recall_DTclassifier_RESAMPLED*100,
      Recall_SVC_resampled*100,
      Recall_LR_resampled*100,
      Recall_NB_resampled*100,
      Recall_AB_resampled*100,
      Recall_KNN_resampled*100,
      Recall_mlp_resampled*100
],
     ["F1_score",
      F1_score_ETC_MA_resampled*100,
      F1_score_RF_resampled*100,
      F1_score_DTclassifier_RESAMPLED*100,
      F1_score_SVC_resampled*100,
      F1_score_LR_resampled*100,
      F1_score_NB_resampled*100,
      F1_score_AB_resampled*100,
      F1_score_KNN_resampled*100,
      F1_score_mlp_resampled*100
]
     ]
df3_table = pd.DataFrame(data_adasyn_classifier, columns=algorithm_classifiers)
df3_table = pd.DataFrame(df3_table).round(2)



print("RESULTS WITHOUT IMBALANCING FOR CLASSIFIER ENSEMBLE ALGORITHMS")
print("=========================================================================")
print(df_table.to_string(index=False))
print("RESULTS WITH IMBALANCING USING ADASYN FOR CLASSIFIER ENSEMBLE ALGORITHMS")
print("=========================================================================")
print(df3_table.to_string(index=False))

"""# Performance Plot with Adasyn"""

import matplotlib.pyplot as plt
import numpy as np

# Define model names and corresponding metric values
models_classifiers = ['ETC', 'RF', 'DTC', 'SVC', 'LR', 'NB', 'AC', 'KNN','NN']
my_color_classifier = ['green', 'red', 'grey', 'black','blue']

# Define the metric values for each model without Adasyn
values_classifiers_adasyn = {
    'Accuracy':(Accuracy_ETC_MA_resampled*100, Accuracy_RF_resampled*100, Accuracy_DTclassifier_RESAMPLED * 100, Accuracy_SVC_resampled*100, Accuracy_LR_resampled*100,
      Accuracy_NB_resampled*100, Accuracy_AB_resampled*100, Accuracy_KNN_resampled*100, Accuracy_mlp_resampled*100),

    'Precision':(Precision_ETC_MA_resampled*100,Precision_RF_resampled*100,Precision_DTclassifier_RESAMPLED* 100, Precision_SVC_resampled*100, Precision_LR_resampled*100,
      Precision_NB_resampled*100, Precision_AB_resampled*100, Precision_KNN_resampled *100, Precision_mlp_resampled*100),

    'Recall':(Recall_ETC_MA_resampled*100, Recall_RF_resampled*100,Recall_DTclassifier_RESAMPLED*100, Recall_SVC_resampled*100,
      Recall_LR_resampled*100, Recall_NB_resampled*100, Recall_AB_resampled*100, Recall_KNN_resampled*100, Recall_mlp_resampled*100),

    'F1 Score':(F1_score_ETC_MA_resampled*100, F1_score_RF_resampled*100, F1_score_DTclassifier_RESAMPLED*100,F1_score_SVC_resampled*100,
      F1_score_LR_resampled*100, F1_score_NB_resampled*100, F1_score_AB_resampled*100, F1_score_KNN_resampled*100, F1_score_mlp_resampled*100)
}

# Plot for the classification
x = np.arange(len(models_classifiers))  # the label locations
width = 0.1  # the width of the bars
multiplier = 0

fig, ax = plt.subplots(figsize=(8, 6))

for attribute, measurement in values_classifiers_adasyn.items():  # classification model values
    offset = width * multiplier
    rects = ax.bar(x + offset, measurement, width, label=attribute, color=my_color_classifier[multiplier])
    multiplier += 1

ax.set_title('Performance Plot of the classification models with Adasyn to compensate for Unbias in the dataset')
ax.set_ylabel('Percentage (%)')
ax.set_xlabel('Models')
ax.set_xticks(x + width * 1.5)
ax.set_xticklabels(models_classifiers)
ax.legend(loc='upper right', ncols=1)
ax.set_ylim(0, 110)

plt.show()

"""# Performance Plot without Adasyn"""

import matplotlib.pyplot as plt
import numpy as np

# Define model names and corresponding metric values
my_color_classifier = ['green', 'red', 'navy', 'orange','blue']

# Define the metric values for each model
# Define the metric values for each model without Adasyn
values_classifiers = {
    'Accuracy':( Accuracy_ETC_MA*100,
      Accuracy_RF*100,
      Accuracy_DTclassifier*100,
      Accuracy_SVC*100,
      Accuracy_LR*100,
      Accuracy_NB*100,
      Accuracy_AB*100,
      Accuracy_KNN*100,
      Accuracy_mlp_classifier*100),

    'Precision':(Precision_ETC_MA*100,
      Precision_RF*100,
      Precision_DTclassifier*100,
      Precision_SVC*100,
      Precision_LR*100,
      Precision_NB*100,
      Precision_AB*100,
      Precision_KNN*100,
      Precision_mlp_classifier*100),

    'Recall':(Recall_ETC_MA*100,
      Recall_RF*100,
      Recall_DTclassifier* 100,
      Recall_SVC*100,
      Recall_LR*100,
      Recall_NB*100,
      Recall_AB*100,
      Recall_KNN*100,
      Recall_mlp_classifier*100),

    'F1 Score':(F1_score_ETC_MA*100,
      F1_score_RF*100,
      F1_score_DTclassifier* 100,
      F1_score_SVC*100,
      F1_score_LR*100,
      F1_score_NB*100,
      F1_score_AB*100,
      F1_score_KNN*100,
      F1_score_mlp_classifier*100)
}

# Plot for the classification
x = np.arange(len(models_classifiers))  # the label locations
width = 0.1  # the width of the bars
multiplier = 0

fig, ax = plt.subplots(figsize=(8, 6))

for attribute, measurement in values_classifiers.items():
    offset = width * multiplier
    rects = ax.bar(x + offset, measurement, width, label=attribute)
    multiplier += 1

ax.set_title('Performance Plot of the classification models without Adasyn')
ax.set_ylabel('Percentage (%)')
ax.set_xlabel('Models')
ax.set_xticks(x + width * 1.5)
ax.set_xticklabels(models_classifiers)
ax.legend(loc='upper right', ncols=1)
ax.set_ylim(0, 110)

plt.show()

"""### Confusion matrix

### With Adasyn for Imbalancing of the dataset
"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# 1 ETC confusion matrix with adasyn
cm = confusion_matrix(y_test, y_pred_ETC_resampled, labels=ETC_resampled.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=ETC_resampled.classes_)
plt.rcParams["figure.figsize"] = (5,2)
disp.plot()
print("Confusion matrix for ETC WITH ADASYN")
plt.show()

# 2 RTC confusion matrix with adasyn
cm = confusion_matrix(y_test, RF_resampled_TEST, labels=RF_resampled.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=RF_resampled.classes_)
plt.rcParams["figure.figsize"] = (5,2)
disp.plot()
print("Confusion matrix for RTC WITH ADASYN")
plt.show()

# 3. SVM confusion matrix with adasyn
# cm = confusion_matrix(y_test, SVM_resampled_TEST, labels=SVM_resampled.classes_)
# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=SVM_resampled.classes_)
# plt.rcParams["figure.figsize"] = (5,2)
# disp.plot()
# print("Confusion matrix for SVM WITH ADASYN")
# plt.show()

# 4.DTC confusion matrix with adasyn
cm = confusion_matrix(y_test, y_pred_RESAMPLED, labels=DTclassifier_RESAMPLED.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=DTclassifier_RESAMPLED.classes_)
plt.rcParams["figure.figsize"] = (5,2)
disp.plot()
print("Confusion matrix for DTC WITH ADASYN")
plt.show()

# 5.LR confusion matrix with adasyn
cm = confusion_matrix(y_test, LR_resampled_TEST, labels=LR_resampled.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=LR_resampled.classes_)
plt.rcParams["figure.figsize"] = (5,2)
disp.plot()
print("Confusion matrix for LR WITH ADASYN")
plt.show()

# 6.NB confusion matrix with adasyn
cm = confusion_matrix(y_test, NB_resampled_TEST, labels=NB_resampled.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=NB_resampled.classes_)
plt.rcParams["figure.figsize"] = (5, 2)
disp.plot()
print("Confusion matrix for NB WITH ADASYN")
plt.show()

# 7.ABABOOST confusion matrix with adasyn
cm = confusion_matrix(y_test, AB_resampled_TEST, labels=AB_resampled.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=AB_resampled.classes_)
plt.rcParams["figure.figsize"] = (5,2)
disp.plot()
print("Confusion matrix for ABABOOST WITH ADASYN")
plt.show()

# 8.KNN confusion matrix with adasyn
cm = confusion_matrix(y_test, KNN_resampled_TEST, labels=KNN_resampled.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=KNN_resampled.classes_)
plt.rcParams["figure.figsize"] = (5,2)
disp.plot()
print("Confusion matrix for KNN WITH ADASYN")
plt.show()

# 9.MLP confusion matrix with adasyn
cm = confusion_matrix(y_test, y_pred_mlp_resampled, labels=mlp_resampled.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=mlp_resampled.classes_)
plt.rcParams["figure.figsize"] = (5,2)
disp.plot()
print("Confusion matrix for MLP WITH ADASYN")
plt.show()

"""### Confusion matrix without adasyn"""

# # 1 ETC confusion matrix with adasyn
# cm = confusion_matrix(y_test, y_pred_AB, labels=AB_MO.classes_)
# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=AB_MO.classes_)
# plt.rcParams["figure.figsize"] = (5,2)
# disp.plot()
# print("Confusion matrix for ETC WITHOUT ADASYN")
# plt.show()

# List the content
# !ls

from google.colab import files

# Download the models to local machine
# files.download('/content/DTC.pkl')
# files.download('/content/ETC.pkl')

